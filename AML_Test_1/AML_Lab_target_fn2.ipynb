{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column 4 as target column:\n",
    "# Team Members:\n",
    "# USN: 01FB15ECS278 Name: Shashank Saran\n",
    "# USN: 01FB15ECS286 Name: Shreyas V Patil\n",
    "# USN: 01FB15ECS289 Name: Siddhanth Vinay\n",
    "# USN: 01FB15ECS290 Name: Siddharth Ganesan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Siddhanth\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colnames=['x1', 'x2', 'y1', 'y2'] \n",
    "dataset_df1 = pd.read_csv('algebra.csv',names=colnames,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature1 = tf.feature_column.numeric_column('x1', dtype=tf.float32, shape=())\n",
    "feature2 = tf.feature_column.numeric_column('x2', dtype=tf.float32, shape=())\n",
    "label1 = tf.feature_column.numeric_column('y1', dtype=tf.float32, shape=())\n",
    "label2 = tf.feature_column.numeric_column('y2', dtype=tf.float32, shape=())\n",
    "feature_cols = [feature1,feature2]\n",
    "feature_name= ['x1','x2']\n",
    "label_name = 'y2'\n",
    "feature_ndarray1 = dataset_df1[feature_name].astype(np.float32)\n",
    "label_ndarray1 = dataset_df1[label_name].astype(np.float32)\n",
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(feature_ndarray1, label_ndarray1, random_state=0, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_input1():\n",
    "    _dataset = tf.data.Dataset.from_tensor_slices(({'x1': x_train1['x1'],'x2': x_train1['x2']}, y_train1))\n",
    "    dataset = _dataset.batch(8)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    features, labels = iterator.get_next()\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def val_input1():\n",
    "    _dataset = tf.data.Dataset.from_tensor_slices(({'x1': x_test1['x1'],'x2': x_test1['x2']}, y_test1))\n",
    "    dataset = _dataset.batch(32)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    features, labels = iterator.get_next()\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_dnn_regression_fn(features, labels, mode, params):\n",
    "    top = tf.feature_column.input_layer(features, params[\"feature_columns\"])\n",
    "    ctr=0\n",
    "    for units in params.get(\"hidden_units\"):\n",
    "        nam=\"hidden_\"+str(ctr)\n",
    "        ctr+=1\n",
    "        top = tf.layers.dense(inputs=top, units=units, activation=tf.nn.relu,name=nam)\n",
    "    output_layer = tf.layers.dense(inputs=top, units=1,name=\"output\")\n",
    "    predictions = tf.squeeze(output_layer, 1)\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions={\"Predict\": predictions})\n",
    "    average_loss = tf.losses.mean_squared_error(labels, predictions)\n",
    "    batch_size = tf.shape(labels)[0]\n",
    "    total_loss = tf.to_float(batch_size) * tf.to_float(average_loss) #tf.to_float\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = params.get(\"optimizer\", tf.train.AdamOptimizer)\n",
    "        optimizer = optimizer(params.get(\"learning_rate\", None))\n",
    "        train_op = optimizer.minimize(\n",
    "        loss=average_loss, global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "        mode=mode, loss=total_loss, train_op=train_op)\n",
    "    assert mode == tf.estimator.ModeKeys.EVAL\n",
    "    rmse = tf.metrics.root_mean_squared_error(labels, predictions)\n",
    "    eval_metrics = {\"rmse\": rmse}\n",
    "    return tf.estimator.EstimatorSpec(mode=mode,\n",
    "    loss=total_loss,\n",
    "    eval_metric_ops=eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class myDNNRegressorEstimator():\n",
    "        def __init__(self,model):\n",
    "            self.model = model\n",
    "        def get_weights(self):\n",
    "            layers = dict()\n",
    "            list_layers = [\"hidden_0\",\"output\"]\n",
    "            for layer in list_layers:\n",
    "                weights = self.model.get_variable_value(layer+\"/kernel\")\n",
    "                weights=np.transpose(weights)\n",
    "                bias = self.model.get_variable_value(layer+\"/bias\")\n",
    "                layers[layer] = {\"weights\":weights,\"bias\":bias}\n",
    "            return layers\n",
    "        def predict(self,val1,val2):\n",
    "                l1=[val1,val2]\n",
    "                weights = self.model.get_variable_value(\"hidden_0/kernel\")\n",
    "                bias = self.model.get_variable_value(\"hidden_0/bias\")\n",
    "                weights=np.transpose(weights)\n",
    "                vals=[]\n",
    "                for i in weights:\n",
    "                    vals.append(np.matmul(np.transpose(np.array(l1)),i))\n",
    "                vals=np.add(vals,bias)\n",
    "                out_weights=self.model.get_variable_value(\"output/kernel\")\n",
    "                out_bias=self.model.get_variable_value(\"output/bias\")\n",
    "                # The line below implements the ReLu activation function.\n",
    "                vals[vals<0]=0\n",
    "                vals=np.matmul(np.transpose(vals),out_weights)\n",
    "                vals=np.add(vals,out_bias)\n",
    "                return vals[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x22855d76668>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.estimator.Estimator(\n",
    "      model_fn= my_dnn_regression_fn,\n",
    "      params={\n",
    "          \"feature_columns\": feature_cols,\n",
    "          \"learning_rate\": 0.01,\n",
    "          \"optimizer\": tf.train.AdamOptimizer,\n",
    "          \"hidden_units\": [10000]\n",
    "      })\n",
    "\n",
    "model.train(input_fn=train_input1, steps=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'global_step': 2125, 'loss': 6435.7285, 'rmse': 14.200452}\n"
     ]
    }
   ],
   "source": [
    "eval_result = model.evaluate(input_fn=val_input1)\n",
    "print(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1:  1 X2:  1 \tValue:  0.9533554813079729\n",
      "X1:  1 X2:  2 \tValue:  0.5726499237876218\n",
      "X1:  2 X2:  1 \tValue:  1.7439258181217467\n",
      "X1:  3 X2:  1 \tValue:  2.945991828137783\n",
      "X1:  3 X2:  2 \tValue:  1.493739767178896\n",
      "X1:  5 X2:  3 \tValue:  2.034124053049819\n",
      "X1:  4 X2:  3 \tValue:  1.5884055884338788\n",
      "X1:  4 X2:  2 \tValue:  2.1495165738866056\n",
      "X1:  1 X2:  3 \tValue:  0.37709056099237626\n"
     ]
    }
   ],
   "source": [
    "myEstimator = myDNNRegressorEstimator(model)\n",
    "#weights = myEstimator.get_weights()\n",
    "#print(weights)\n",
    "list1=[[1,1],[1,2],[2,1],[3,1],[3,2],[5,3],[4,3],[4,2],[1,3]]\n",
    "list2=[]\n",
    "for i in list1:\n",
    "    list2.append(myEstimator.predict(i[0],i[1]))\n",
    "for i in range(len(list1)):\n",
    "    print(\"X1: \",list1[i][0],\"X2: \",list1[i][1],\"\\tValue: \",list2[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From the above output values, it can be determined that the output function is X1/X2"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
